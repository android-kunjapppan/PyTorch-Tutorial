{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1zkbOeh6oYVq5Rli8UIoJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/android-kunjapppan/PyTorch-Tutorial/blob/master/Pytorch_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hQCZlGR8Mh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wih3VXJ9j_Y",
        "colab_type": "text"
      },
      "source": [
        "# Lazy Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-MPP-rW8U1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILE ='model.pth'\n",
        "torch.save(model,FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPD7SC608Ylz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.load(FILE)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ndDMAi981N2",
        "colab_type": "text"
      },
      "source": [
        "# Prefered Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmWKjkZi81u-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY8Q2cmp869Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(*args,**kwargs) # E.g., Model(n_input_features = 6)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHrm3Aqc-6Xy",
        "colab_type": "text"
      },
      "source": [
        "# State Dictionary of the Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZtNIv3s-8Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
        "print(optim.state_dict())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opxMHfT7_Qof",
        "colab_type": "text"
      },
      "source": [
        "# To save a Checkpoint while Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHGdAVGF_KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = {\n",
        "    'epoch': 90,\n",
        "    'model_state': model.state_dict(),\n",
        "    'optim_state': optimizer.state_dict(),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWb6mxTf_lPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(checkpoint,'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvYhwKPJ_xS-",
        "colab_type": "text"
      },
      "source": [
        "# **TO Load a Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42EHkOaH_13r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_checkpoint = torch.load('checkpoint.pth')\n",
        "\n",
        "# TO access the epochs\n",
        "epoch = loaded_checkpoint['epoch']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyu1D-HVABWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(n_input_features = 6)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h388BDjkAQgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37z-1Re0AoUI",
        "colab_type": "text"
      },
      "source": [
        "# when you are using a GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKc6GQ5mAqte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SAVE \n",
        "\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(),FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sk9W0D6BP_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading into a GPU\n",
        "\n",
        "model = Model(*args,**kwargs)\n",
        "mdoel.load_state_dict(torch.load(FILE))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Athf4n2dA49H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading into a CPU \n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = Model(*args,**kwargs)\n",
        "mdoel.load_state_dict(torch.load(FILE,map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnamiybBBi_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save on CPU and LOAD on a GPU\n",
        "\n",
        "torch.save(model.state_dict(),FILE)\n",
        "\n",
        "# load\n",
        "device = torch.device('cuda')\n",
        "model = Model(*args,**kwargs)\n",
        "model.load_state_dict(torch.load(FILE,map_location='cuda:0')) # CHOOSE whatever GPU Number\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}